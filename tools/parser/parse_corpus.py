import sys
from pathlib import Path
import yaml
import html
import logging
from tree_sitter_language_pack import get_parser

# ---------- Configuration ----------
BASE_DIR = Path(__file__).resolve().parents[2]
RAW_DIR = BASE_DIR / "corpus_raw"
TEI_DIR = BASE_DIR / "corpus_tei"
LANGMAP_YML = BASE_DIR / "tools" / "parser" / "langmap.yml"
CLASSMAP_YML = BASE_DIR / "tools" / "parser" / "classmap.yml"

# ロギングの設定
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# デバッグモード
DEBUG = False

DEFAULT_LANGMAP = {
    ".pde": "java",
    ".py": "python",
    ".java": "java",
    ".js": "javascript",
    ".cpp": "cpp",
    ".cs": "csharp",
    ".clj": "clojure",
    ".c": "c",
    ".rb": "ruby",
    ".sh": "bash",
    ".html": "html",
}

DEFAULT_CLASSMAP = {
    "string_literal": "icon",
    "number_literal": "icon",
    "comment": "icon",
    "identifier": "index",
    "type_identifier": "symbol",
    "primitive_type": "symbol",
    "operator": "symbol",
    "keyword": "symbol"
}

def load_yaml_map(path: Path, default: dict) -> dict:
    if path.exists():
        return {k: v for k, v in yaml.safe_load(path.read_text()).items()}
    return default

def print_node_tree(node, indent=0):
    """ノード構造をツリー形式で出力"""
    text = node.text.decode('utf8', errors='replace')
    if len(text) > 50:
        text = text[:47] + "..."
    text = text.replace('\n', '\\n')
    print(f"{' ' * indent}{node.type}: '{text}' ({node.start_point[0]}:{node.start_point[1]}-{node.end_point[0]}:{node.end_point[1]})")
    for child in node.children:
        print_node_tree(child, indent + 2)

def extract_tokens(node, classmap):
    """最小のアトミックトークンのみを抽出"""
    if not node.children:
        # 子がないノードはアトミック
        cls = classmap.get(node.type)
        if cls:
            s_line, s_col = node.start_point
            e_line, e_col = node.end_point
            return [(cls, s_line + 1, s_col, e_line + 1, e_col)]
        return []
    
    # 子ノードからトークンを収集
    tokens = []
    for child in node.children:
        tokens.extend(extract_tokens(child, classmap))
    return tokens

def extract_tokens_bottom_up(code_bytes, parser, classmap):
    """ボトムアップアプローチで重複のないトークンを抽出"""
    tree = parser.parse(code_bytes)
    
    if DEBUG:
        print("\nNode Tree:")
        print_node_tree(tree.root_node)
    
    # 最小のトークンを抽出
    all_tokens = extract_tokens(tree.root_node, classmap)
    
    # 位置順にソート
    all_tokens.sort(key=lambda x: (x[1], x[2], -x[3], -x[4]))
    
    # 重複を排除し、重なりを解決
    non_overlapping_tokens = []
    last_end = (-1, -1)  # (行, 列)
    
    for cls, sl, sc, el, ec in all_tokens:
        start_pos = (sl, sc)
        end_pos = (el, ec)
        
        # 前のトークンと重なっていない場合のみ追加
        if start_pos >= last_end:
            non_overlapping_tokens.append((cls, sl, sc, el, ec))
            last_end = end_pos
    
    return non_overlapping_tokens

def parse_and_tei(src: Path, lang_key: str, classmap: dict):
    parser = get_parser(lang_key)
    code = src.read_bytes()
    lines = code.decode(errors="replace").splitlines()
    
    # ボトムアップアプローチでトークンを抽出
    tokens = extract_tokens_bottom_up(code, parser, classmap)
    
    # TEI line elements
    line_elements = [
        f'        <l xml:id="l{n+1}">{html.escape(line, quote=False)}</l>'
        for n, line in enumerate(lines)
    ]
    
    # トークンからTEIスパンを生成
    spans = [
        f'        <span ana="#{cls}" from="#l{sl}:{sc}" to="#l{el}:{ec}"/>'
        for cls, sl, sc, el, ec in tokens
    ]
    
    # TEI XMLを生成
    tei_xml = (
        '<?xml version="1.0" encoding="UTF-8"?>\n'
        '<TEI xmlns="http://www.tei-c.org/ns/1.0">\n'
        '  <teiHeader>\n'
        '    <fileDesc>\n'
        f'      <titleStmt><title>{src.name}</title></titleStmt>\n'
        '      <publicationStmt><p>Generated by parse_corpus.py</p></publicationStmt>\n'
        '      <sourceDesc><p>Original source code</p></sourceDesc>\n'
        '    </fileDesc>\n'
        '  </teiHeader>\n'
        '  <text>\n'
        '    <body>\n'
        '      <div type="code" xml:lang="en">\n'
        + "\n".join(line_elements) + '\n'
        '      </div>\n'
        '    </body>\n'
        '  </text>\n'
        '  <standOff>\n'
        '    <spanGrp type="static-class">\n'
        + "\n".join(spans) + '\n'
        '    </spanGrp>\n'
        '  </standOff>\n'
        '</TEI>\n'
    )
    
    # 出力を保存
    TEI_DIR.mkdir(exist_ok=True, parents=True)
    out_path = TEI_DIR / (src.stem + ".xml")
    out_path.write_text(tei_xml, encoding="utf-8")
    print(f"✓ {src.name} → {out_path.relative_to(BASE_DIR)}")

def main():
    # コマンドライン引数の処理
    global DEBUG
    args = []
    for arg in sys.argv[1:]:
        if arg == "--debug":
            DEBUG = True
        else:
            args.append(arg)
    
    # 設定の読み込み
    langmap = load_yaml_map(LANGMAP_YML, DEFAULT_LANGMAP)
    classmap = load_yaml_map(CLASSMAP_YML, DEFAULT_CLASSMAP)
    
    # 処理対象ファイルの決定
    src_paths = args
    if not src_paths:
        src_paths = sorted(RAW_DIR.glob("*"))
    
    # 各ファイルの処理
    for path_str in src_paths:
        src_path = Path(path_str)
        if not src_path.exists():
            print(f"File not found: {src_path}")
            continue
        
        key = langmap.get(src_path.suffix.lower())
        if not key:
            print(f"✗ skip (no parser): {src_path.name}")
            continue
        
        try:
            parse_and_tei(src_path, key, classmap)
        except Exception as e:
            print(f"Error processing {src_path.name}: {e}")
            if DEBUG:
                import traceback
                traceback.print_exc()

if __name__ == "__main__":
    main()
